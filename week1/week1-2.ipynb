{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 機械学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目次\n",
    "\n",
    "- 項目の説明\n",
    "- 欠損値の扱い\n",
    "- カテゴリ変数の扱い"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section2 データの解説"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Googleドライブのマウント（Colab使いのみ）\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# %cd /content/drive/MyDrive/dlc/week1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 図表が使えるようにする\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのロード\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"./data/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 項目の説明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先頭3行を表示\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PassengerId – 乗客識別ユニークID\n",
    "- Survived – 生存フラグ（0=死亡、1=生存）　←　これを予測する\n",
    "- Pclass – チケットクラス（1st, 2nd, 3rd）\n",
    "- Name – 乗客の名前\n",
    "- Sex – 性別（male=男性、female＝女性）\n",
    "- Age – 年齢\n",
    "- SibSp – タイタニックに同乗している兄弟/配偶者の数\n",
    "- Parch – タイタニックに同乗している親/子供の数\n",
    "- Ticket – チケット番号\n",
    "- Fare – 料金\n",
    "- Cabin – 客室番号\n",
    "- Embarked – タイタニックへ乗った港（C=Cherbourg, S=Southampton, Q=Queenstown）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのサイズを確認\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの欠損・型を確認\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損率を確認\n",
    "\n",
    "def nullCountFig(df):\n",
    "    null_val = df.isnull().sum()\n",
    "    percent = 100 * df.isnull().sum()/len(df)\n",
    "    counted_table = pd.concat([null_val, percent], axis=1)\n",
    "    counted_figure = counted_table.rename(\n",
    "        columns = {0 : '欠損数', 1 : '欠損率(%)'}\n",
    "    )\n",
    "    return counted_figure\n",
    "\n",
    "nullCountFig(data)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 欠損値の扱い\n",
    "\n",
    "欠損には大きく3種類あります。\n",
    "\n",
    "- 完全にランダムに欠損\n",
    "- 観測データに依存する欠損（特定のデータの中でランダムに欠損）\n",
    "- 欠損データに依存する欠損（ランダムではない）\n",
    "\n",
    "これらを考慮した上で、欠損値に対応する主な方針は4つです。\n",
    "\n",
    "1. 欠損のある行、列を除外する\n",
    "2. 何らかの値で埋める（単変量補完】\n",
    "3. 何らかの値で埋める（多変量補完）\n",
    "4. 欠損値を受け入れてくれるモデルを使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損のある行番号を取得\n",
    "\n",
    "miss_index = data[data.isnull().any(axis=1)].index\n",
    "miss_age_index = data[data['Age'].isnull()].index\n",
    "miss_cabin_index = data[data['Cabin'].isnull()].index\n",
    "miss_embarked_index = data[data['Embarked'].isnull()].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 欠損のある行、列を除外する\n",
    "\n",
    "メリット：かんたん\n",
    "\n",
    "デメリット：予測性能の低下を招きやすい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特定のデータを除外する\n",
    "\n",
    "non_null_data1 = data.drop(['Age', 'Cabin', 'Embarked'], axis=1)\n",
    "display(non_null_data1.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特定のデータを取り出す（上と同じ）\n",
    "\n",
    "non_null_data2 = data[['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'SibSp', 'Parch', 'Ticket', 'Fare']]\n",
    "display(non_null_data2.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値が一つでも含まれる列を除外する\n",
    "\n",
    "non_null_data3 = data.dropna()\n",
    "display(non_null_data3.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 何らかの値で埋める（単変量補完）\n",
    "\n",
    "メリット：かんたん\n",
    "\n",
    "デメリット：欠損が多いと効果薄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight(df):\n",
    "    styles = df.copy()\n",
    "    styles.iloc[[miss_age_index], :] = 'background-color: red'\n",
    "    return styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 共通の値（0）で埋める\n",
    "\n",
    "simple_filled_data1 = data.fillna(0)\n",
    "display(simple_filled_data1.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平均値で埋める\n",
    "\n",
    "## 平均値：.mean()\n",
    "## 中央値：.median()\n",
    "## 最瀕値：.mode()\n",
    "simple_filled_data2 = data.fillna(data.mean())\n",
    "display(simple_filled_data2.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直前or直後の値で埋める（時系列データ向き）\n",
    "\n",
    "## 直前：method='ffill'\n",
    "## 直後：method='bfill'\n",
    "simple_filled_data3 = data.fillna(method = 'ffill')\n",
    "display(simple_filled_data3.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 何らかの値で埋める（多変量補完）\n",
    "\n",
    "メリット：予測精度が高くなりがち\n",
    "\n",
    "デメリット：うまくいかなかった時、原因がわからないがち"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 数値だけのデータを作る\n",
    "only_num_data = data.drop(['PassengerId', 'Survived', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'], axis=1)\n",
    "only_num_data_columns = only_num_data.columns\n",
    "\n",
    "# ヒストグラムを作る関数\n",
    "def figmake(df, key):\n",
    "    x_bin = 50\n",
    "    x_max = df[key].max()\n",
    "    x_min = df[key].min()\n",
    "    bins = np.linspace(x_min, x_max, x_bin)\n",
    "    plt.figure()\n",
    "    plt.hist(only_num_data[key], bins=bins, color='red', alpha=0.5)\n",
    "    plt.hist(df[key], bins=bins, color='blue', alpha=0.5)\n",
    "    plt.title(key)\n",
    "    plt.ylabel('count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベイジアンブリッジを使う\n",
    "\n",
    "bayesian = pd.DataFrame(\n",
    "                IterativeImputer().fit_transform(only_num_data)\n",
    "                , columns=only_num_data_columns\n",
    "            )\n",
    "\n",
    "display(bayesian)\n",
    "figmake(bayesian, 'Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ランダムフォレストを使う\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "randf = pd.DataFrame(\n",
    "            IterativeImputer(RandomForestRegressor()).fit_transform(only_num_data)\n",
    "            , columns=only_num_data_columns\n",
    "        )\n",
    "\n",
    "display(randf)\n",
    "figmake(randf, 'Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNNを使う\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "knn = pd.DataFrame(\n",
    "            KNNImputer(n_neighbors=2).fit_transform(only_num_data)\n",
    "            , columns=only_num_data_columns\n",
    "        )\n",
    "\n",
    "display(knn)\n",
    "figmake(knn, 'Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 欠損値を受け入れてくれるモデルを使う\n",
    "\n",
    "メリット：予測精度が高くなりがち\n",
    "\n",
    "デメリット：ちょっとめんどくさい\n",
    "\n",
    "XGBoost, LightGBMが有名"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 カテゴリ変数の扱い\n",
    "\n",
    "文字列のままでは基本的にモデルへ入力することができないため、代わりとなる数値に変換する必要があります。\n",
    "\n",
    "また、文字列データのみならず質的なデータは量的なデータに比べ扱いにくい場合があります。\n",
    "\n",
    "そこで、[A,B,C]のような複数の値のある要素をAの有無という形式 **（ダミー変数 (Dummie variable)）** に変換することで扱いやすくします。この処理を **One-Hot エンコーディング (One hot encodring)** といいます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 乗船港のみのデータ作成\n",
    "embarked_data = data['Embarked'].dropna()\n",
    "\n",
    "# エンコーダの定義\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "display(\n",
    "    pd.DataFrame(\n",
    "        encoder.fit_transform(embarked_data.values.reshape(-1, 1))\n",
    "        ,columns=encoder.categories_\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 特徴量エンジニアリング\n",
    "\n",
    "**特徴量エンジニアリング (Feature engineering)** とは、機械学習​​モデル​の性能​を向上させるために、今あるデータの特徴量から新たな特徴量を構築することです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コピーを作る\n",
    "\n",
    "fe_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 何人家族で乗船したかという特徴量を作る\n",
    "\n",
    "fe_data['family_size'] = fe_data['SibSp'] + fe_data['Parch'] + 1\n",
    "\n",
    "fig,ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "# 生存者と死亡者の数を確認\n",
    "sns.countplot(fe_data['family_size'],hue=data['Survived'], ax=ax[0])\n",
    "# family_sizeごとの生存率を確認\n",
    "sns.barplot(x='family_size', y='Survived', data=fe_data, color='orange', ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 名前の敬称という特徴量を作る\n",
    "\n",
    "fe_data['honorific'] = fe_data['Name'].map(lambda x: x.split(', ')[1].split('. ')[0])\n",
    "\n",
    "print(fe_data['honorific'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 似ている敬称をまとめる\n",
    "\n",
    "fe_data['honorific'].replace(['Capt', 'Col', 'Major', 'Dr', 'Rev'], 'Officer', inplace=True)\n",
    "fe_data['honorific'].replace(['Don', 'Sir',  'the Countess', 'Lady', 'Dona', 'Jonkheer'], 'Royalty', inplace=True)\n",
    "fe_data['honorific'].replace(['Mme', 'Ms'], 'Mrs', inplace=True)\n",
    "fe_data['honorific'].replace(['Mlle'], 'Miss', inplace=True)\n",
    "\n",
    "print(fe_data['honorific'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 敬称ごとの年齢を確認\n",
    "\n",
    "# Ageの欠損がないデータを作成\n",
    "fe_data_age = fe_data.dropna(subset=['Age']).copy()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.boxplot(x='honorific', y='Age', data=fe_data_age, color='coral')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7cf671263d4c51f2d66b480f72e1e8058975d5cfc878dca772fd6bfe3ea757f9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('colab': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
