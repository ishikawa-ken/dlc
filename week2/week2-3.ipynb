{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxDwH5Ao-t_a"
      },
      "source": [
        "# ニューラルネットワーク入門"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 3 Pytorchでの実装"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BFooUB9-EXF",
        "outputId": "35bda307-a045-4c1a-caa0-89de75092583"
      },
      "outputs": [],
      "source": [
        "# # Googleドライブのマウント（Colab使いのみ）\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# %cd /content/drive/MyDrive/dlc/week2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxGtp1xw-2cW"
      },
      "outputs": [],
      "source": [
        "# 図表が使えるようにする\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.set()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dataset : データを一つのデータベースにまとめる"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rO53yVOt_MKs"
      },
      "outputs": [],
      "source": [
        "# MNISTをインポートする\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "train_Dataset = datasets.MNIST(\n",
        "    './data'\n",
        "    , train=True\n",
        "    , download=True \n",
        "    , transform=transforms.ToTensor()\n",
        ")\n",
        "\n",
        "test_dataset = datasets.MNIST(\n",
        "    './data'\n",
        "    , train=False\n",
        "    , transform=transforms.ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nX3Y2XGjH1Fx",
        "outputId": "1486a8ed-65c9-4e06-9088-85b55ced1124"
      },
      "outputs": [],
      "source": [
        "# 数を確認\n",
        "\n",
        "print('train_Dataset size: ', len(train_Dataset))  \n",
        "print('test_dataset size: ', len(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "34aCWJ_sD7sy",
        "outputId": "6350f1f5-1582-46d7-f0ee-42bedc321634"
      },
      "outputs": [],
      "source": [
        "# データを確認してみる\n",
        "\n",
        "plot_num = 5\n",
        "\n",
        "fig, axes = plt.subplots(1, plot_num)\n",
        "for i in range(plot_num):\n",
        "    axes[i].imshow(train_Dataset[i][0].view(-1, 28), cmap='gray')\n",
        "    axes[i].set_axis_off()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTBNFZn8KBkF"
      },
      "outputs": [],
      "source": [
        "# 学習データと検証データの分割\n",
        "\n",
        "import torch \n",
        "\n",
        "train_dataset, valid_dataset = torch.utils.data.random_split(\n",
        "    train_Dataset\n",
        "    , [50000, 10000]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CZnOwr-L11v",
        "outputId": "b3cf7ccc-55a2-482b-d2a8-1ba3761d9308"
      },
      "outputs": [],
      "source": [
        "# 数を確認\n",
        "\n",
        "print('train_dataset size: ', len(train_dataset)) \n",
        "print('valid_dataset size: ', len(valid_dataset)) \n",
        "print('test_dataset size: ', len(test_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DataLoader : データをミニバッチ単位で取り出す "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZ4-2zxwA_hl"
      },
      "outputs": [],
      "source": [
        "# ミニバッチごとに取り出す\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset\n",
        "    , batch_size=batch_size \n",
        "    , shuffle=True\n",
        ")\n",
        "\n",
        "valid_loader = DataLoader(\n",
        "    dataset=valid_dataset\n",
        "    , batch_size=batch_size \n",
        "    , shuffle=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset\n",
        "    , batch_size=batch_size\n",
        "    , shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGfRrWK7HQRP"
      },
      "outputs": [],
      "source": [
        "# ネットワークの定義\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# クラス数\n",
        "num_classes = 10\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28*1, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoxXDqNGMki7"
      },
      "outputs": [],
      "source": [
        "# デバイスに転送\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = MLP().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUAW0QcuRViK",
        "outputId": "faab7129-de30-4937-89bb-b37c1eb6555a"
      },
      "outputs": [],
      "source": [
        "# ネットワークの構造を確認\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0eVusq8R0ew"
      },
      "outputs": [],
      "source": [
        "# 損失関数と最適化手法を設定\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "# 損失関数: 交差エントロピー\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化手法: 確率的勾配降下法\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1エポックの訓練を行う関数\n",
        "\n",
        "- `net.train()` : trainモードに変換\n",
        "- `optimizer.zero_grad()` : 勾配を0にリセットする（勾配はbackwardメソッドが実行されるたびに積算されるため必要）\n",
        "- `outputs` : 順伝搬の出力を計算\n",
        "- `loss` : 出力とミニバッチのラベルからコスト関数を計算\n",
        "- `loss.backward()` : lossの勾配を計算\n",
        "- `optimizer.step()` : パラメータを更新"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnv4CukHSqNm"
      },
      "outputs": [],
      "source": [
        "# 1エポックの訓練を行う関数を定義\n",
        "\n",
        "def train1Epoch(model, optimizer, criterion, dataloader, device):\n",
        "    # 学習モードに切り替え\n",
        "    model.train()\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    # ミニバッチ回数実行\n",
        "    for i, (images, labels) in enumerate(dataloader):\n",
        "        # viewで28x28x1を1次元配列に変換し、deviceへ転送\n",
        "        images, labels = images.view(-1, 28*28*1).to(device), labels.to(device)\n",
        "        # 勾配をリセット\n",
        "        optimizer.zero_grad()\n",
        "        # 順伝搬の計算\n",
        "        outputs = model(images)\n",
        "        # lossの計算\n",
        "        loss = criterion(outputs, labels)\n",
        "        # accの計算\n",
        "        acc = (outputs.max(1)[1] == labels).sum()\n",
        "        train_acc += acc.item()\n",
        "        # 逆伝搬の計算\n",
        "        loss.backward()\n",
        "        # 重みの更新\n",
        "        optimizer.step()\n",
        "        # lossのミニバッチ分を加算\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # lossとaccの平均を計算\n",
        "    avg_train_loss = train_loss / len(train_loader.dataset)\n",
        "    avg_train_acc = train_acc / len(train_loader.dataset)\n",
        "\n",
        "    return avg_train_loss, avg_train_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "推論するための関数\n",
        "\n",
        "- `net.eval()` : networkを評価モードに変換\n",
        "- `with torch.no_grad()` : 逆伝搬が必要ないので余計な勾配計算を回避\n",
        "- `outputs` : 予測値を計算"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWv9DqhiThG4"
      },
      "outputs": [],
      "source": [
        "# 推論するための関数を定義\n",
        "\n",
        "def inference(model, optimizer, criterion, dataloader, device):\n",
        "    # 評価モードに切り替え\n",
        "    model.eval()\n",
        "    test_loss, test_acc = 0, 0\n",
        "\n",
        "    # 評価するとき勾配を計算しないように加える\n",
        "    with torch.no_grad():\n",
        "        for j, (images, labels) in enumerate(test_loader):\n",
        "            images, labels = images.view(-1, 28*28*1).to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item()\n",
        "            acc = (outputs.max(1)[1] == labels).sum()\n",
        "            test_acc += acc.item()\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_loader.dataset)\n",
        "    avg_test_acc = test_acc / len(test_loader.dataset)\n",
        "\n",
        "    return avg_test_loss, avg_test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCWPOH-NWhLo"
      },
      "outputs": [],
      "source": [
        "# 学習を行う関数の定義\n",
        "\n",
        "def run(num_epochs, optimizer, criterion, device):\n",
        "    train_loss_list, train_acc_list, valid_loss_list, valid_acc_list = [], [], [], []\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, train_acc = train1Epoch(model, optimizer, criterion, train_loader, device)\n",
        "        valid_loss, valid_acc = inference(model, optimizer, criterion, valid_loader, device)\n",
        "\n",
        "        print ('Epoch [{}/{}], Loss: {loss:.4f}, valid_loss: {valid_loss:.4f}, valid_acc: {valid_acc:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, loss=train_loss, valid_loss=valid_loss, valid_acc=valid_acc))\n",
        "        \n",
        "        train_loss_list.append(train_loss)\n",
        "        train_acc_list.append(train_acc)\n",
        "        valid_loss_list.append(valid_loss)\n",
        "        valid_acc_list.append(valid_acc)\n",
        "\n",
        "    return train_loss_list, train_acc_list, valid_loss_list, valid_acc_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w767RFfdY3-Z",
        "outputId": "00b31995-73be-4349-a87a-5365e236346e"
      },
      "outputs": [],
      "source": [
        "# 学習の実行\n",
        "\n",
        "epoch = 20\n",
        "train_loss_list, train_acc_list, valid_loss_list, valid_acc_list = run(epoch, optimizer, criterion, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaBnyY7sZdlF"
      },
      "outputs": [],
      "source": [
        "# lossの推移をplot\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(range(epoch), train_loss_list, color='blue', linestyle='-', label='train_loss')\n",
        "plt.plot(range(epoch), valid_loss_list, color='green', linestyle='--', label='valid_loss')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.grid() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEOgAgoha6kI"
      },
      "outputs": [],
      "source": [
        "# accの推移をplot\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(range(epoch), train_acc_list, color='blue', linestyle='-', label='train_acc')\n",
        "plt.plot(range(epoch), valid_acc_list, color='green', linestyle='--', label='valid_acc')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcFrN_PJbYRw"
      },
      "outputs": [],
      "source": [
        "# 学習結果を確認\n",
        "\n",
        "# datasetからサンプルを一つ取り出す\n",
        "image, label = train_dataset[0]\n",
        "sample = train_dataset[0][0].view(-1, 28*28).to(device)\n",
        "\n",
        "# 学習後のモデルで予測\n",
        "prediction_label = torch.argmax(model(sample))\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.imshow(sample.to('cpu').detach().numpy().reshape(28, 28))\n",
        "ax.axis('off')\n",
        "ax.set_title(f'True Label : {label}, Prediction : {prediction_label}', fontsize=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# テストデータでAccを確認\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    test_acc = 0\n",
        "    for images, labels in test_loader:        \n",
        "        images, labels = images.view(-1, 28 * 28 * 1 ).to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        test_acc += (outputs.max(1)[1] == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "    print('test_accuracy: {} %'.format(100 * test_acc / total)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 学習済みの重みとバイアスを保存\n",
        "\n",
        "torch.save(model.state_dict(), 'mnist_model.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# クラス数\n",
        "num_classes = 10\n",
        "\n",
        "# Multi Layer Perceptron Network\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28*1, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# select device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = MLP().to(device)\n",
        " \n",
        "# optimizing\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "###  training\n",
        "print ('training start ...')\n",
        "num_epochs = 50   \n",
        " \n",
        "# initialize list for plot graph after training\n",
        "train_loss_list, train_acc_list, valid_loss_list, valid_acc_list = [], [], [], []\n",
        " \n",
        "for epoch in range(num_epochs):\n",
        "    # initialize each epoch\n",
        "    train_loss, train_acc, valid_loss, valid_acc = 0, 0, 0, 0\n",
        "    \n",
        "    # ======== train_mode ======\n",
        "    model.train()\n",
        "    for i, (images, labels) in enumerate(train_loader):  # ミニバッチ回数実行\n",
        "        #viewで28×28×１画像を１次元に変換し、deviceへ転送\n",
        "        images, labels = images.view(-1, 28*28*1).to(device), labels.to(device)\n",
        "        optimizer.zero_grad()  # 勾配リセット\n",
        "        outputs = model(images)  # 順伝播の計算\n",
        "        loss = criterion(outputs, labels)  # lossの計算\n",
        "        train_loss += loss.item()  # train_loss に結果を蓄積\n",
        "        acc = (outputs.max(1)[1] == labels).sum()  #  予測とラベルが合っている数の合計\n",
        "        train_acc += acc.item()  # train_acc に結果を蓄積\n",
        "        loss.backward()  # 逆伝播の計算        \n",
        "        optimizer.step()  # 重みの更新\n",
        "        avg_train_loss = train_loss / len(train_loader.dataset)  # lossの平均を計算\n",
        "        avg_train_acc = train_acc / len(train_loader.dataset)  # accの平均を計算\n",
        "\n",
        "    \n",
        "    # ======== valid_mode ======\n",
        "    model.eval()\n",
        "    with torch.no_grad():  # 必要のない計算を停止\n",
        "      for images, labels in valid_loader:        \n",
        "          images, labels = images.view(-1, 28*28*1).to(device), labels.to(device)\n",
        "          outputs = model(images)\n",
        "          loss = criterion(outputs, labels)\n",
        "          valid_loss += loss.item()\n",
        "          acc = (outputs.max(1)[1] == labels).sum()\n",
        "          valid_acc += acc.item()\n",
        "    avg_valid_loss = valid_loss / len(valid_loader.dataset)\n",
        "    avg_valid_acc = valid_acc / len(valid_loader.dataset)\n",
        "    \n",
        "    # print log\n",
        "    print ('Epoch [{}/{}], Loss: {loss:.4f}, val_loss: {valid_loss:.4f}, val_acc: {valid_acc:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, loss=avg_train_loss, valid_loss=avg_valid_loss, valid_acc=avg_valid_acc))\n",
        " \n",
        "    # append list for polt graph after training\n",
        "    train_loss_list.append(avg_train_loss)\n",
        "    train_acc_list.append(avg_train_acc)\n",
        "    valid_loss_list.append(avg_valid_loss)\n",
        "    valid_acc_list.append(avg_valid_acc)\n",
        "    \n",
        "# ======== fainal test ======\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    test_acc = 0\n",
        "    for images, labels in test_loader:        \n",
        "        images, labels = images.view(-1, 28 * 28 * 1 ).to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        test_acc += (outputs.max(1)[1] == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "    print('test_accuracy: {} %'.format(100 * test_acc / total)) \n",
        " \n",
        "# save weights\n",
        "torch.save(model.state_dict(), 'mnist_model.ckpt')\n",
        " \n",
        "# plot graph \n",
        "plt.figure()\n",
        "plt.plot(range(num_epochs), train_loss_list, color='blue', linestyle='-', label='train_loss')\n",
        "plt.plot(range(num_epochs), valid_loss_list, color='green', linestyle='--', label='valid_loss')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.grid()\n",
        " \n",
        "plt.figure()\n",
        "plt.plot(range(num_epochs), train_acc_list, color='blue', linestyle='-', label='train_acc')\n",
        "plt.plot(range(num_epochs), valid_acc_list, color='green', linestyle='--', label='valid_acc')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.grid()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "week2-3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
