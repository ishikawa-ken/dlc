{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Food-20ã‚³ãƒ³ãƒš \n",
        "ï½è»¢ç§»å­¦ç¿’/ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç·¨ï½"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BFooUB9-EXF",
        "outputId": "35bda307-a045-4c1a-caa0-89de75092583"
      },
      "outputs": [],
      "source": [
        "# # Googleãƒ‰ãƒ©ã‚¤ãƒ–ã®ãƒã‚¦ãƒ³ãƒˆï¼ˆColabä½¿ã„ã®ã¿ï¼‰\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# %cd /content/drive/MyDrive/dlc/week3.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxGtp1xw-2cW"
      },
      "outputs": [],
      "source": [
        "# å›³è¡¨ãŒä½¿ãˆã‚‹ã‚ˆã†ã«ã™ã‚‹\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxDwH5Ao-t_a"
      },
      "source": [
        "## ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# èª­ã¿è¾¼ã¿å‡¦ç†\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# ğŸ’¡è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¹\n",
        "train_path = '../input/train/'\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåŒ–\n",
        "full_dataset = ImageFolder(train_path)\n",
        "\n",
        "# ã‚µã‚¤ã‚ºç¢ºèª\n",
        "print(f'full size: {len(full_dataset)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®å‰²åˆã‚’æ±ºã‚ã‚ˆã†"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²ã™ã‚‹\n",
        "\n",
        "import torch\n",
        "\n",
        "# ğŸ’¡è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å‰²åˆ\n",
        "train_ratio = 0.8\n",
        "\n",
        "# å„ãƒ‡ãƒ¼ã‚¿ã®æ•°ã‚’ç®—å‡º\n",
        "train_size = int(train_ratio * len(full_dataset))\n",
        "valid_size = len(full_dataset) - train_size\n",
        "\n",
        "# ãƒ©ãƒ³ãƒ€ãƒ ã«åˆ†å‰²\n",
        "train_dataset, valid_dataset = torch.utils.data.random_split(\n",
        "    full_dataset, [train_size, valid_size]\n",
        ")\n",
        "\n",
        "# ã‚µã‚¤ã‚ºç¢ºèª\n",
        "print(f'train: {len(train_dataset)}, valid: {len(valid_dataset)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### å‰å‡¦ç†ã‚’å®šç¾©ã—ã‚ˆã†\n",
        "\n",
        "å‚è€ƒï¼š\n",
        "\n",
        "* [Pytorchå…¬å¼ - torchvision.transforms](https://pytorch.org/vision/stable/transforms.html)\n",
        "* [torchvision ã§ä½¿ãˆã‚‹ Transform ã¾ã¨ã‚](https://pystyle.info/pytorch-list-of-transforms/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å‰å‡¦ç†ã®å®šç¾©\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç”¨å‰å‡¦ç†\n",
        "train_transform = transforms.Compose([\n",
        "    # ğŸ’¡è‰²ã€…è©¦ã—ã¦ã¿ã‚ˆã†\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2009, 0.1984, 0.2023))\n",
        "])\n",
        "\n",
        "# æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿&ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”¨å‰å‡¦ç†\n",
        "valid_transform = transforms.Compose([\n",
        "    # ğŸ’¡è‰²ã€…è©¦ã—ã¦ã¿ã‚ˆã†\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2009, 0.1984, 0.2023))\n",
        "])\n",
        "\n",
        "# å‰å‡¦ç†ã®é©ç”¨\n",
        "train_dataset.dataset.transform = train_transform\n",
        "valid_dataset.dataset.transform = valid_transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ãƒŸãƒ‹ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’æ±ºã‚ã‚ˆã†"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DataLoaderã‚’ä½œæˆ\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# ğŸ’¡ãƒŸãƒ‹ãƒãƒƒãƒã‚µã‚¤ã‚º\n",
        "batch_size = 128\n",
        "\n",
        "# è¨“ç·´ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼\n",
        "valid_loader = DataLoader(\n",
        "    dataset=valid_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ç•ªå·ã¨ã‚¯ãƒ©ã‚¹ã®è¾æ›¸\n",
        "class_label = {\n",
        "    0 : 'apple_pie',\n",
        "    1 : 'cheesecake',\n",
        "    2 : 'chocolate_cake', \n",
        "    3 : 'donuts', \n",
        "    4 : 'french_fries',\n",
        "    5 : 'french_toast',\n",
        "    6 : 'fried_rice',\n",
        "    7 : 'hamburger',\n",
        "    8 : 'ice_cream',\n",
        "    9 : 'miso_soup',\n",
        "    10: 'oysters',\n",
        "    11: 'pizza',\n",
        "    12: 'ramen',\n",
        "    13: 'sashimi',\n",
        "    14: 'spaghetti_bolognese',\n",
        "    15: 'spaghetti_carbonara',\n",
        "    16: 'steak',\n",
        "    17: 'sushi',\n",
        "    18: 'takoyaki',\n",
        "    19: 'waffles'\n",
        "}\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ã‹ã‚‰ç”»åƒã¨ãƒ©ãƒ™ãƒ«ã®ãƒ†ãƒ³ã‚½ãƒ«ã‚’å–ã‚Šå‡ºã™\n",
        "def showBatch(dl):\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    for images, labels in dl:\n",
        "        for i in range(5):\n",
        "            plt.subplot(1, 5, i+1)\n",
        "            plt.imshow(np.transpose(images[i].numpy(), (1, 2, 0)))\n",
        "            plt.title(class_label[int(labels[i].numpy())])\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª\n",
        "showBatch(train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ãƒ¢ãƒ‡ãƒ«ã‚’æ±ºã‚ã‚ˆã†\n",
        "\n",
        "å‚è€ƒï¼š\n",
        "\n",
        "* [torchvision.models](https://pytorch.org/vision/stable/models.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å®šç¾©\n",
        "\n",
        "from torchvision import models\n",
        "\n",
        "# ã‚¯ãƒ©ã‚¹æ•°\n",
        "num_classes = 20\n",
        "\n",
        "# ğŸ’¡ãƒ¢ãƒ‡ãƒ«(Resnet34)ã‚’ãƒ­ãƒ¼ãƒ‰\n",
        "model = models.resnet34(pretrained=True)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# æœ€çµ‚å±¤ã‚’å¤‰æ›´\n",
        "model.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "# ğŸ’¡è»¢ç§»å­¦ç¿’ãªã‚‰False/ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãªã‚‰True\n",
        "FT = True\n",
        "if FT == True:\n",
        "    # å…¨ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®é‡ã¿ã‚’å›ºå®š\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # æœ€çµ‚å±¤ã ã‘é‡ã¿å›ºå®šã‚’è§£é™¤\n",
        "    last_layer = list(model.children())[-1]\n",
        "    for param in last_layer.parameters():\n",
        "        param.requires_grad = True\n",
        "else:\n",
        "    pass\n",
        "\n",
        "# ãƒ‡ãƒã‚¤ã‚¹ã«è»¢é€\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### æå¤±é–¢æ•°ã¨æœ€é©åŒ–æ‰‹æ³•ã‚’æ±ºã‚ã‚ˆã†\n",
        "\n",
        "å‚è€ƒï¼š\n",
        "\n",
        "* [torch.nn - Loss Functionsï¼ˆæå¤±é–¢æ•°ï¼‰](https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
        "* [torch.optim - Algorithmsï¼ˆæœ€é©åŒ–æ‰‹æ³•ï¼‰](https://pytorch.org/docs/stable/optim.html#algorithms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æå¤±é–¢æ•°ã¨æœ€é©åŒ–æ‰‹æ³•ã‚’è¨­å®š\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "# ğŸ’¡æå¤±é–¢æ•°: äº¤å·®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# ğŸ’¡æœ€é©åŒ–æ‰‹æ³•: Adam\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### å­¦ç¿’å›æ•°ã‚’æ±ºã‚ã‚ˆã†"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ’¡ã‚¨ãƒãƒƒã‚¯æ•°\n",
        "num_epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# lossã¨accè¨˜éŒ²ç”¨ãƒªã‚¹ãƒˆ\n",
        "train_loss_list, train_acc_list, valid_loss_list, valid_acc_list = [], [], [], []\n",
        "\n",
        "# æœ€å°lossä¿å­˜ç”¨\n",
        "min_valid_loss = 10000000\n",
        "\n",
        "# é‡ã¿ãƒ•ã‚¡ã‚¤ãƒ«\n",
        "CKPT_FILE = 'food20_tl_best.ckpt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ã„ã–å­¦ç¿’"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å­¦ç¿’\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "print ('Training start ...')\n",
        "\n",
        "# äº‹å‰ã«è¡Œã£ãŸã‚¨ãƒãƒƒã‚¯æ•°\n",
        "ad_epochs = len(train_loss_list)\n",
        " \n",
        "for epoch in tqdm(range(num_epochs), desc='Epoch'):\n",
        "    \n",
        "    # ã‚¨ãƒãƒƒã‚¯æ•°ã®é€šçŸ¥\n",
        "    print(f'Epoch [{ad_epochs+epoch+1}/{ad_epochs+num_epochs}]')\n",
        "    \n",
        "    # ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«åˆæœŸåŒ–\n",
        "    train_loss, train_acc, valid_loss, valid_acc = 0, 0, 0, 0\n",
        "    \n",
        "    # ====== è¨“ç·´ãƒ¢ãƒ¼ãƒ‰ ======\n",
        "    model.train()\n",
        "\n",
        "    # ãƒŸãƒ‹ãƒãƒƒãƒã®æ•°å®Ÿè¡Œ\n",
        "    for images, labels in tqdm(train_loader, leave=False, desc='Train'):\n",
        "        # deviceã¸è»¢é€\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        \n",
        "        # å‹¾é…ã‚’ãƒªã‚»ãƒƒãƒˆ\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # é †ä¼æ¬ã®è¨ˆç®—\n",
        "        outputs = model(images)\n",
        "        \n",
        "        # lossã¨accã®è¨ˆç®—\n",
        "        loss = criterion(outputs, labels)\n",
        "        train_loss += loss.item()\n",
        "        acc = (outputs.max(1)[1] == labels).sum()\n",
        "        train_acc += acc.item()\n",
        "        \n",
        "        # é€†ä¼æ¬ã®è¨ˆç®—\n",
        "        loss.backward()\n",
        "        # é‡ã¿ã®æ›´æ–°\n",
        "        optimizer.step()\n",
        "\n",
        "        # lossã¨accã®å¹³å‡ã‚’è¨ˆç®—\n",
        "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
        "        avg_train_acc = train_acc / len(train_loader.dataset)\n",
        "\n",
        "    \n",
        "    # ====== æ¤œè¨¼ãƒ¢ãƒ¼ãƒ‰ ======\n",
        "    model.eval()\n",
        "    \n",
        "    # å¿…è¦ã®ãªã„è¨ˆç®—ã‚’åœæ­¢\n",
        "    with torch.no_grad():\n",
        "        # ãƒŸãƒ‹ãƒãƒƒãƒã®æ•°å®Ÿè¡Œ\n",
        "        for images, labels in tqdm(valid_loader, leave=False, desc='Valid'):\n",
        "            # deviceã¸è»¢é€      \n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            \n",
        "            # ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›\n",
        "            outputs = model(images)\n",
        "            \n",
        "            # lossã¨accã®è¨ˆç®—\n",
        "            loss = criterion(outputs, labels)\n",
        "            valid_loss += loss.item()\n",
        "            acc = (outputs.max(1)[1] == labels).sum()\n",
        "            valid_acc += acc.item()\n",
        "    \n",
        "    # lossã¨accã®å¹³å‡ã‚’è¨ˆç®—\n",
        "    avg_valid_loss = valid_loss / len(valid_loader.dataset)\n",
        "    avg_valid_acc = valid_acc / len(valid_loader.dataset)\n",
        "    \n",
        "    # ãƒ­ã‚°ã®å‡ºåŠ›\n",
        "    print (\n",
        "        f'train_loss: {avg_train_loss:.4f}, train_acc: {avg_train_acc:.4f}, ' \\\n",
        "        f'val_loss: {avg_valid_loss:.4f}, val_acc: {avg_valid_acc:.4f}' \n",
        "    )\n",
        "\n",
        "    # ä¸€ç•ªlossãŒä½ã„ã‚¨ãƒãƒƒã‚¯ã®é‡ã¿ã‚’ä¿å­˜\n",
        "    if avg_valid_loss < min_valid_loss:\n",
        "        print('Save best model ...')\n",
        "        min_valid_loss = avg_valid_loss\n",
        "        torch.save(model.state_dict(), CKPT_FILE)\n",
        "\n",
        "    print('====================')\n",
        "     \n",
        "    # ã‚°ãƒ©ãƒ•è¡¨ç¤ºç”¨ãƒªã‚¹ãƒˆã«ä¿å­˜\n",
        "    train_loss_list.append(avg_train_loss)\n",
        "    train_acc_list.append(avg_train_acc)\n",
        "    valid_loss_list.append(avg_valid_loss)\n",
        "    valid_acc_list.append(avg_valid_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ã‚°ãƒ©ãƒ•ã®è¡¨ç¤º\n",
        "plt.figure()\n",
        "plt.plot(range(1, len(train_loss_list)+1), train_loss_list, color='blue', linestyle='-', label='train_loss')\n",
        "plt.plot(range(1, len(valid_loss_list)+1), valid_loss_list, color='green', linestyle='--', label='valid_loss')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.grid()\n",
        " \n",
        "plt.figure()\n",
        "plt.plot(range(1, len(train_acc_list)+1), train_acc_list, color='blue', linestyle='-', label='train_acc')\n",
        "plt.plot(range(1, len(valid_acc_list)+1), valid_acc_list, color='green', linestyle='--', label='valid_acc')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã®æº–å‚™"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Datasetã‚¯ãƒ©ã‚¹å®šç¾©\n",
        "\n",
        "import glob\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MyTestDataset(Dataset):\n",
        "    def __init__(self, test_image_dir, transform=None):\n",
        "        self.image_paths = sorted(glob.glob(test_image_dir + '/*.jpg'))\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_path = self.image_paths[index]\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# ğŸ’¡è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¹\n",
        "test_path = '../input/test/'\n",
        "\n",
        "# DatasetåŒ–\n",
        "test_dataset = MyTestDataset(test_image_dir=test_path, transform=valid_transform)\n",
        "\n",
        "# DataLoaderåŒ–\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿\n",
        "best_model = models.resnet34()\n",
        "best_model.fc = nn.Linear(512, num_classes)\n",
        "best_model.load_state_dict(torch.load(CKPT_FILE))\n",
        "best_model.to(device)\n",
        "\n",
        "# çµæœä¿å­˜ç”¨\n",
        "preds = []\n",
        "\n",
        "# è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰\n",
        "best_model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images in test_loader:\n",
        "        # deviceã¸è»¢é€      \n",
        "        images = images.to(device)\n",
        "        # ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›\n",
        "        outputs = best_model.forward(images)\n",
        "        # çµæœä¿å­˜\n",
        "        preds.append((torch.argmax(outputs, dim=1)).to('cpu').numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "out_df = pd.DataFrame()\n",
        "out_df['ImageName'] = [f'{str(i).zfill(4)}.jpg' for i in range(1, len(preds)+1)]\n",
        "out_df['Label'] = np.concatenate(preds, axis=0)\n",
        "\n",
        "out_df.to_csv('submission2.csv', index=None)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "week2-3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
