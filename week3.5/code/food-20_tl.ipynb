{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Food-20コンペ \n",
        "～転移学習/ファインチューニング編～"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BFooUB9-EXF",
        "outputId": "35bda307-a045-4c1a-caa0-89de75092583"
      },
      "outputs": [],
      "source": [
        "# # Googleドライブのマウント（Colab使いのみ）\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# %cd /content/drive/MyDrive/dlc/week3.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxGtp1xw-2cW"
      },
      "outputs": [],
      "source": [
        "# 図表が使えるようにする\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxDwH5Ao-t_a"
      },
      "source": [
        "## データの準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### データの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 読み込み処理\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# 💡訓練データのパス\n",
        "train_path = '../input/train/'\n",
        "\n",
        "# データセット化\n",
        "full_dataset = ImageFolder(train_path)\n",
        "\n",
        "# サイズ確認\n",
        "print(f'full size: {len(full_dataset)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 訓練データと検証データの割合を決めよう"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 訓練データと検証データに分割する\n",
        "\n",
        "import torch\n",
        "\n",
        "# 💡訓練データの割合\n",
        "train_ratio = 0.8\n",
        "\n",
        "# 各データの数を算出\n",
        "train_size = int(train_ratio * len(full_dataset))\n",
        "valid_size = len(full_dataset) - train_size\n",
        "\n",
        "# ランダムに分割\n",
        "train_dataset, valid_dataset = torch.utils.data.random_split(\n",
        "    full_dataset, [train_size, valid_size]\n",
        ")\n",
        "\n",
        "# サイズ確認\n",
        "print(f'train: {len(train_dataset)}, valid: {len(valid_dataset)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 前処理を定義しよう\n",
        "\n",
        "参考：\n",
        "\n",
        "* [Pytorch公式 - torchvision.transforms](https://pytorch.org/vision/stable/transforms.html)\n",
        "* [torchvision で使える Transform まとめ](https://pystyle.info/pytorch-list-of-transforms/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 前処理の定義\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "# 訓練データ用前処理\n",
        "train_transform = transforms.Compose([\n",
        "    # 💡色々試してみよう\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2009, 0.1984, 0.2023))\n",
        "])\n",
        "\n",
        "# 検証データ&テストデータ用前処理\n",
        "valid_transform = transforms.Compose([\n",
        "    # 💡色々試してみよう\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2009, 0.1984, 0.2023))\n",
        "])\n",
        "\n",
        "# 前処理の適用\n",
        "train_dataset.dataset.transform = train_transform\n",
        "valid_dataset.dataset.transform = valid_transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ミニバッチサイズを決めよう"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DataLoaderを作成\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 💡ミニバッチサイズ\n",
        "batch_size = 128\n",
        "\n",
        "# 訓練用データローダー\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# 検証用データローダー\n",
        "valid_loader = DataLoader(\n",
        "    dataset=valid_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 番号とクラスの辞書\n",
        "class_label = {\n",
        "    0 : 'apple_pie',\n",
        "    1 : 'cheesecake',\n",
        "    2 : 'chocolate_cake', \n",
        "    3 : 'donuts', \n",
        "    4 : 'french_fries',\n",
        "    5 : 'french_toast',\n",
        "    6 : 'fried_rice',\n",
        "    7 : 'hamburger',\n",
        "    8 : 'ice_cream',\n",
        "    9 : 'miso_soup',\n",
        "    10: 'oysters',\n",
        "    11: 'pizza',\n",
        "    12: 'ramen',\n",
        "    13: 'sashimi',\n",
        "    14: 'spaghetti_bolognese',\n",
        "    15: 'spaghetti_carbonara',\n",
        "    16: 'steak',\n",
        "    17: 'sushi',\n",
        "    18: 'takoyaki',\n",
        "    19: 'waffles'\n",
        "}\n",
        "\n",
        "# データローダから画像とラベルのテンソルを取り出す\n",
        "def showBatch(dl):\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    for images, labels in dl:\n",
        "        for i in range(5):\n",
        "            plt.subplot(1, 5, i+1)\n",
        "            plt.imshow(np.transpose(images[i].numpy(), (1, 2, 0)))\n",
        "            plt.title(class_label[int(labels[i].numpy())])\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# データの確認\n",
        "showBatch(train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 学習済みモデルの準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### モデルを決めよう\n",
        "\n",
        "参考：\n",
        "\n",
        "* [torchvision.models](https://pytorch.org/vision/stable/models.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ネットワーク定義\n",
        "\n",
        "from torchvision import models\n",
        "\n",
        "# クラス数\n",
        "num_classes = 20\n",
        "\n",
        "# 💡モデル(Resnet34)をロード\n",
        "model = models.resnet34(pretrained=True)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 最終層を変更\n",
        "model.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "# 💡転移学習ならFalse/ファインチューニングならTrue\n",
        "FT = True\n",
        "if FT == True:\n",
        "    # 全レイヤーの重みを固定\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # 最終層だけ重み固定を解除\n",
        "    last_layer = list(model.children())[-1]\n",
        "    for param in last_layer.parameters():\n",
        "        param.requires_grad = True\n",
        "else:\n",
        "    pass\n",
        "\n",
        "# デバイスに転送\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 損失関数と最適化手法を決めよう\n",
        "\n",
        "参考：\n",
        "\n",
        "* [torch.nn - Loss Functions（損失関数）](https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
        "* [torch.optim - Algorithms（最適化手法）](https://pytorch.org/docs/stable/optim.html#algorithms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 損失関数と最適化手法を設定\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "# 💡損失関数: 交差エントロピー\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 💡最適化手法: Adam\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 学習回数を決めよう"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 💡エポック数\n",
        "num_epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# lossとacc記録用リスト\n",
        "train_loss_list, train_acc_list, valid_loss_list, valid_acc_list = [], [], [], []\n",
        "\n",
        "# 最小loss保存用\n",
        "min_valid_loss = 10000000\n",
        "\n",
        "# 重みファイル\n",
        "CKPT_FILE = 'food20_tl_best.ckpt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### いざ学習"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 学習\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "print ('Training start ...')\n",
        "\n",
        "# 事前に行ったエポック数\n",
        "ad_epochs = len(train_loss_list)\n",
        " \n",
        "for epoch in tqdm(range(num_epochs), desc='Epoch'):\n",
        "    \n",
        "    # エポック数の通知\n",
        "    print(f'Epoch [{ad_epochs+epoch+1}/{ad_epochs+num_epochs}]')\n",
        "    \n",
        "    # エポックごとに初期化\n",
        "    train_loss, train_acc, valid_loss, valid_acc = 0, 0, 0, 0\n",
        "    \n",
        "    # ====== 訓練モード ======\n",
        "    model.train()\n",
        "\n",
        "    # ミニバッチの数実行\n",
        "    for images, labels in tqdm(train_loader, leave=False, desc='Train'):\n",
        "        # deviceへ転送\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        \n",
        "        # 勾配をリセット\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # 順伝搬の計算\n",
        "        outputs = model(images)\n",
        "        \n",
        "        # lossとaccの計算\n",
        "        loss = criterion(outputs, labels)\n",
        "        train_loss += loss.item()\n",
        "        acc = (outputs.max(1)[1] == labels).sum()\n",
        "        train_acc += acc.item()\n",
        "        \n",
        "        # 逆伝搬の計算\n",
        "        loss.backward()\n",
        "        # 重みの更新\n",
        "        optimizer.step()\n",
        "\n",
        "        # lossとaccの平均を計算\n",
        "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
        "        avg_train_acc = train_acc / len(train_loader.dataset)\n",
        "\n",
        "    \n",
        "    # ====== 検証モード ======\n",
        "    model.eval()\n",
        "    \n",
        "    # 必要のない計算を停止\n",
        "    with torch.no_grad():\n",
        "        # ミニバッチの数実行\n",
        "        for images, labels in tqdm(valid_loader, leave=False, desc='Valid'):\n",
        "            # deviceへ転送      \n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            \n",
        "            # モデル出力\n",
        "            outputs = model(images)\n",
        "            \n",
        "            # lossとaccの計算\n",
        "            loss = criterion(outputs, labels)\n",
        "            valid_loss += loss.item()\n",
        "            acc = (outputs.max(1)[1] == labels).sum()\n",
        "            valid_acc += acc.item()\n",
        "    \n",
        "    # lossとaccの平均を計算\n",
        "    avg_valid_loss = valid_loss / len(valid_loader.dataset)\n",
        "    avg_valid_acc = valid_acc / len(valid_loader.dataset)\n",
        "    \n",
        "    # ログの出力\n",
        "    print (\n",
        "        f'train_loss: {avg_train_loss:.4f}, train_acc: {avg_train_acc:.4f}, ' \\\n",
        "        f'val_loss: {avg_valid_loss:.4f}, val_acc: {avg_valid_acc:.4f}' \n",
        "    )\n",
        "\n",
        "    # 一番lossが低いエポックの重みを保存\n",
        "    if avg_valid_loss < min_valid_loss:\n",
        "        print('Save best model ...')\n",
        "        min_valid_loss = avg_valid_loss\n",
        "        torch.save(model.state_dict(), CKPT_FILE)\n",
        "\n",
        "    print('====================')\n",
        "     \n",
        "    # グラフ表示用リストに保存\n",
        "    train_loss_list.append(avg_train_loss)\n",
        "    train_acc_list.append(avg_train_acc)\n",
        "    valid_loss_list.append(avg_valid_loss)\n",
        "    valid_acc_list.append(avg_valid_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# グラフの表示\n",
        "plt.figure()\n",
        "plt.plot(range(1, len(train_loss_list)+1), train_loss_list, color='blue', linestyle='-', label='train_loss')\n",
        "plt.plot(range(1, len(valid_loss_list)+1), valid_loss_list, color='green', linestyle='--', label='valid_loss')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.grid()\n",
        " \n",
        "plt.figure()\n",
        "plt.plot(range(1, len(train_acc_list)+1), train_acc_list, color='blue', linestyle='-', label='train_acc')\n",
        "plt.plot(range(1, len(valid_acc_list)+1), valid_acc_list, color='green', linestyle='--', label='valid_acc')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 提出ファイルの準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### テストデータの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Datasetクラス定義\n",
        "\n",
        "import glob\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MyTestDataset(Dataset):\n",
        "    def __init__(self, test_image_dir, transform=None):\n",
        "        self.image_paths = sorted(glob.glob(test_image_dir + '/*.jpg'))\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_path = self.image_paths[index]\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 💡訓練データのパス\n",
        "test_path = '../input/test/'\n",
        "\n",
        "# Dataset化\n",
        "test_dataset = MyTestDataset(test_image_dir=test_path, transform=valid_transform)\n",
        "\n",
        "# DataLoader化\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 学習したモデルの読み込み\n",
        "best_model = models.resnet34()\n",
        "best_model.fc = nn.Linear(512, num_classes)\n",
        "best_model.load_state_dict(torch.load(CKPT_FILE))\n",
        "best_model.to(device)\n",
        "\n",
        "# 結果保存用\n",
        "preds = []\n",
        "\n",
        "# 評価モード\n",
        "best_model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images in test_loader:\n",
        "        # deviceへ転送      \n",
        "        images = images.to(device)\n",
        "        # モデル出力\n",
        "        outputs = best_model.forward(images)\n",
        "        # 結果保存\n",
        "        preds.append((torch.argmax(outputs, dim=1)).to('cpu').numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "out_df = pd.DataFrame()\n",
        "out_df['ImageName'] = [f'{str(i).zfill(4)}.jpg' for i in range(1, len(preds)+1)]\n",
        "out_df['Label'] = np.concatenate(preds, axis=0)\n",
        "\n",
        "out_df.to_csv('submission2.csv', index=None)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "week2-3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
