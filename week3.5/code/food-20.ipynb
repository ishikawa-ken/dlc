{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Food-20ã‚³ãƒ³ãƒš\n",
        "\n",
        "ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã“ã®ã¾ã¾ã§ã‚‚æœ€ä½é™å‹•ä½œã™ã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "ãƒã‚¤ã‚¹ã‚³ã‚¢ã‚’ç›®æŒ‡ã™ã«ã¯æ”¹è‰¯ãŒå¿…è¦ã§ã™ã€‚æ”¹è‰¯ãƒã‚¤ãƒ³ãƒˆã«ã¯`# ğŸ’¡ãªã«ã‹ã—ã‚‰`ã¨ã‚³ãƒ¡ãƒ³ãƒˆãŒã‚ã‚Šã¾ã™ã€‚\n",
        "\n",
        "| ãƒ¬ãƒ™ãƒ«æ„Ÿ | ã‚„ã‚‹ã“ã¨ |\n",
        "| :--: | :-- |\n",
        "| **ç§€æ‰** | ãã®ã¾ã¾æå‡ºã—ã¦ã¿ã‚ˆã†ã€‚|\n",
        "| **å¤©æ‰** | ã“ã®ã‚³ãƒ¼ãƒ‰ã‚’æ”¹è‰¯ã—ã¦ã€ãƒã‚¤ã‚¹ã‚³ã‚¢ã‚’ç›®æŒ‡ãã†ã€‚ |\n",
        "| **é¬¼æ‰** | è»¢ç§»å­¦ç¿’/FTã«æŒ‘æˆ¦ã—ã¦ã¿ã‚ˆã†ã€‚ |\n",
        "| **å¥‡æ‰** | â€ æ›´ãªã‚‹é«˜ã¿ã¸â€  |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BFooUB9-EXF",
        "outputId": "35bda307-a045-4c1a-caa0-89de75092583"
      },
      "outputs": [],
      "source": [
        "# # Googleãƒ‰ãƒ©ã‚¤ãƒ–ã®ãƒã‚¦ãƒ³ãƒˆï¼ˆColabä½¿ã„ã®ã¿ï¼‰\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# %cd /content/drive/MyDrive/dlc/week3.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxGtp1xw-2cW"
      },
      "outputs": [],
      "source": [
        "# å›³è¡¨ãŒä½¿ãˆã‚‹ã‚ˆã†ã«ã™ã‚‹\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxDwH5Ao-t_a"
      },
      "source": [
        "## ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿\n",
        "\n",
        "```\n",
        "dataset1\n",
        "â”œâ”€â”€ class1\n",
        "â”‚   â”œâ”€â”€ a.jpg\n",
        "â”‚   â”œâ”€â”€ ãƒ»ãƒ»ãƒ»\n",
        "â”‚\n",
        "â”œâ”€â”€ class2\n",
        "â”‚   â”œâ”€â”€ a.jpg\n",
        "â”‚   â”œâ”€â”€ ãƒ»ãƒ»ãƒ»\n",
        "ãƒ»ãƒ»ãƒ»\n",
        "\n",
        "```\n",
        "â†‘ã®ã‚ˆã†ã«ã€ã‚¯ãƒ©ã‚¹ã«å¯¾å¿œã—ãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ãŒåˆ†ã‘ã‚‰ã‚Œã¦ã„ã‚‹å ´åˆã€torchvisionã®[ImageFolder](https://pytorch.org/vision/main/generated/torchvision.datasets.ImageFolder.html)ã‚’åˆ©ç”¨ã§ãã¾ã™ã€‚ï¼ˆè‡ªä½œDatasetã‚¯ãƒ©ã‚¹ã‚’ä½œã‚‹å¿…è¦ãŒãªããªã‚‹ï¼‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# èª­ã¿è¾¼ã¿å‡¦ç†\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# ğŸ’¡è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¹\n",
        "train_path = '../input/train/'\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåŒ–\n",
        "full_dataset = ImageFolder(train_path)\n",
        "\n",
        "# ã‚µã‚¤ã‚ºç¢ºèª\n",
        "print(f'full size: {len(full_dataset)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®å‰²åˆã‚’æ±ºã‚ã‚ˆã†"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²ã™ã‚‹\n",
        "\n",
        "import torch\n",
        "\n",
        "# ğŸ’¡è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å‰²åˆ\n",
        "train_ratio = 0.8\n",
        "\n",
        "# å„ãƒ‡ãƒ¼ã‚¿ã®æ•°ã‚’ç®—å‡º\n",
        "train_size = int(train_ratio * len(full_dataset))\n",
        "valid_size = len(full_dataset) - train_size\n",
        "\n",
        "# ãƒ©ãƒ³ãƒ€ãƒ ã«åˆ†å‰²\n",
        "train_dataset, valid_dataset = torch.utils.data.random_split(\n",
        "    full_dataset, [train_size, valid_size]\n",
        ")\n",
        "\n",
        "# ã‚µã‚¤ã‚ºç¢ºèª\n",
        "print(f'train: {len(train_dataset)}, valid: {len(valid_dataset)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### å‰å‡¦ç†ã‚’å®šç¾©ã—ã‚ˆã†\n",
        "\n",
        "å‚è€ƒï¼š\n",
        "\n",
        "* [Pytorchå…¬å¼ - torchvision.transforms](https://pytorch.org/vision/stable/transforms.html)\n",
        "* [torchvision ã§ä½¿ãˆã‚‹ Transform ã¾ã¨ã‚](https://pystyle.info/pytorch-list-of-transforms/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å‰å‡¦ç†ã®å®šç¾©\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç”¨å‰å‡¦ç†\n",
        "train_transform = transforms.Compose([\n",
        "    # ğŸ’¡è‰²ã€…è©¦ã—ã¦ã¿ã‚ˆã†\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2009, 0.1984, 0.2023))\n",
        "])\n",
        "\n",
        "# æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿&ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”¨å‰å‡¦ç†\n",
        "valid_transform = transforms.Compose([\n",
        "    # ğŸ’¡è‰²ã€…è©¦ã—ã¦ã¿ã‚ˆã†\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2009, 0.1984, 0.2023))\n",
        "])\n",
        "\n",
        "# å‰å‡¦ç†ã®é©ç”¨\n",
        "train_dataset.dataset.transform = train_transform\n",
        "valid_dataset.dataset.transform = valid_transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ãƒŸãƒ‹ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’æ±ºã‚ã‚ˆã†"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DataLoaderã‚’ä½œæˆ\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# ğŸ’¡ãƒŸãƒ‹ãƒãƒƒãƒã‚µã‚¤ã‚º\n",
        "batch_size = 128\n",
        "\n",
        "# è¨“ç·´ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼\n",
        "valid_loader = DataLoader(\n",
        "    dataset=valid_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ç•ªå·ã¨ã‚¯ãƒ©ã‚¹ã®è¾æ›¸\n",
        "class_label = {\n",
        "    0 : 'apple_pie',\n",
        "    1 : 'cheesecake',\n",
        "    2 : 'chocolate_cake', \n",
        "    3 : 'donuts', \n",
        "    4 : 'french_fries',\n",
        "    5 : 'french_toast',\n",
        "    6 : 'fried_rice',\n",
        "    7 : 'hamburger',\n",
        "    8 : 'ice_cream',\n",
        "    9 : 'miso_soup',\n",
        "    10: 'oysters',\n",
        "    11: 'pizza',\n",
        "    12: 'ramen',\n",
        "    13: 'sashimi',\n",
        "    14: 'spaghetti_bolognese',\n",
        "    15: 'spaghetti_carbonara',\n",
        "    16: 'steak',\n",
        "    17: 'sushi',\n",
        "    18: 'takoyaki',\n",
        "    19: 'waffles'\n",
        "}\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ã‹ã‚‰ç”»åƒã¨ãƒ©ãƒ™ãƒ«ã®ãƒ†ãƒ³ã‚½ãƒ«ã‚’å–ã‚Šå‡ºã™\n",
        "def showBatch(dl):\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    for images, labels in dl:\n",
        "        for i in range(5):\n",
        "            plt.subplot(1, 5, i+1)\n",
        "            plt.imshow(np.transpose(images[i].numpy(), (1, 2, 0)))\n",
        "            plt.title(class_label[int(labels[i].numpy())])\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª\n",
        "showBatch(train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æº–å‚™"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æ§‹ç¯‰ã—ã‚ˆã†\n",
        "\n",
        "å¿…è¦ï¼š\n",
        "\n",
        "* **[Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)** ... ç•³ã¿è¾¼ã¿å±¤\n",
        "* **[MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html)** ... æœ€å¤§å€¤ãƒ—ãƒ¼ãƒªãƒ³ã‚°å±¤\n",
        "* **[Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)** ... å…¨çµåˆå±¤\n",
        "* **[Flatten](https://pytorch.org/docs/stable/generated/torch.flatten.html)** ... ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼ˆå…¨çµåˆå±¤å‰ã«å…¥ã‚Œã‚‹ï¼‰\n",
        "* **[(activations)](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)** ... ãŠå¥½ããªæ´»æ€§åŒ–é–¢æ•°\n",
        "\n",
        "ã‚¢ãƒ¬ãƒ³ã‚¸ï¼š\n",
        "* **[Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html)** ... ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆ\n",
        "* **[BatchNorm2d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html)** ... ãƒãƒƒãƒæ­£è¦åŒ–ï¼ˆ2æ¬¡å…ƒï¼šConv2d, MaxPool2dã®ç›´å¾Œï¼‰\n",
        "* **[BatchNorm1d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html)** ... ãƒãƒƒãƒæ­£è¦åŒ–ï¼ˆ1æ¬¡å…ƒï¼šLinearã®ç›´å¾Œï¼‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å®šç¾©\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ã‚¯ãƒ©ã‚¹æ•°\n",
        "num_classes = 20\n",
        "\n",
        "# ã‚¯ãƒ©ã‚¹å®šç¾©\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        # ğŸ’¡ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æœ¬ä½“\n",
        "        self.network = nn.Sequential(\n",
        "            # å…¥åŠ›ç”»åƒã‚µã‚¤ã‚º:3x128x128\n",
        "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # nn.BatchNorm2d(16),\n",
        "\n",
        "            # 16x64x64\n",
        "            nn.Conv2d(16, 32, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # 32x32x32\n",
        "            nn.Conv2d(32, 64, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # 64x16x16\n",
        "            nn.Conv2d(64, 128, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # 128x8x8\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128*8*8, 512),\n",
        "            # nn.Dropout(p=0.5),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            \n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    # é †ä¼æ¬\n",
        "    def forward(self, x):\n",
        "        return self.network(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ãƒ‡ãƒã‚¤ã‚¹ã«è»¢é€\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = Net().to(device)\n",
        "\n",
        "# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ç¢ºèª\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### æå¤±é–¢æ•°ã¨æœ€é©åŒ–æ‰‹æ³•ã‚’æ±ºã‚ã‚ˆã†\n",
        "\n",
        "å‚è€ƒï¼š\n",
        "\n",
        "* [torch.nn - Loss Functionsï¼ˆæå¤±é–¢æ•°ï¼‰](https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
        "* [torch.optim - Algorithmsï¼ˆæœ€é©åŒ–æ‰‹æ³•ï¼‰](https://pytorch.org/docs/stable/optim.html#algorithms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æå¤±é–¢æ•°ã¨æœ€é©åŒ–æ‰‹æ³•ã‚’è¨­å®š\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "# ğŸ’¡æå¤±é–¢æ•°: äº¤å·®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# ğŸ’¡æœ€é©åŒ–æ‰‹æ³•: Adam\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### å­¦ç¿’å›æ•°ã‚’æ±ºã‚ã‚ˆã†"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ’¡ã‚¨ãƒãƒƒã‚¯æ•°\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# lossã¨accè¨˜éŒ²ç”¨ãƒªã‚¹ãƒˆ\n",
        "train_loss_list, train_acc_list, valid_loss_list, valid_acc_list = [], [], [], []\n",
        "\n",
        "# æœ€å°lossä¿å­˜ç”¨\n",
        "min_valid_loss = 10000000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ã„ã–å­¦ç¿’"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å­¦ç¿’\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "print ('Training start ...')\n",
        "\n",
        "# äº‹å‰ã«è¡Œã£ãŸã‚¨ãƒãƒƒã‚¯æ•°\n",
        "ad_epochs = len(train_loss_list)\n",
        " \n",
        "for epoch in tqdm(range(num_epochs), desc='Epoch'):\n",
        "    \n",
        "    # ã‚¨ãƒãƒƒã‚¯æ•°ã®é€šçŸ¥\n",
        "    print(f'Epoch [{ad_epochs+epoch+1}/{ad_epochs+num_epochs}]')\n",
        "    \n",
        "    # ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«åˆæœŸåŒ–\n",
        "    train_loss, train_acc, valid_loss, valid_acc = 0, 0, 0, 0\n",
        "    \n",
        "    # ====== è¨“ç·´ãƒ¢ãƒ¼ãƒ‰ ======\n",
        "    model.train()\n",
        "\n",
        "    # ãƒŸãƒ‹ãƒãƒƒãƒã®æ•°å®Ÿè¡Œ\n",
        "    for images, labels in tqdm(train_loader, leave=False, desc='Train'):\n",
        "        # deviceã¸è»¢é€\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        \n",
        "        # å‹¾é…ã‚’ãƒªã‚»ãƒƒãƒˆ\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # é †ä¼æ¬ã®è¨ˆç®—\n",
        "        outputs = model(images)\n",
        "        \n",
        "        # lossã¨accã®è¨ˆç®—\n",
        "        loss = criterion(outputs, labels)\n",
        "        train_loss += loss.item()\n",
        "        acc = (outputs.max(1)[1] == labels).sum()\n",
        "        train_acc += acc.item()\n",
        "        \n",
        "        # é€†ä¼æ¬ã®è¨ˆç®—\n",
        "        loss.backward()\n",
        "        # é‡ã¿ã®æ›´æ–°\n",
        "        optimizer.step()\n",
        "\n",
        "        # lossã¨accã®å¹³å‡ã‚’è¨ˆç®—\n",
        "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
        "        avg_train_acc = train_acc / len(train_loader.dataset)\n",
        "\n",
        "    \n",
        "    # ====== æ¤œè¨¼ãƒ¢ãƒ¼ãƒ‰ ======\n",
        "    model.eval()\n",
        "    \n",
        "    # å¿…è¦ã®ãªã„è¨ˆç®—ã‚’åœæ­¢\n",
        "    with torch.no_grad():\n",
        "        # ãƒŸãƒ‹ãƒãƒƒãƒã®æ•°å®Ÿè¡Œ\n",
        "        for images, labels in tqdm(valid_loader, leave=False, desc='Valid'):\n",
        "            # deviceã¸è»¢é€      \n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            \n",
        "            # ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›\n",
        "            outputs = model(images)\n",
        "            \n",
        "            # lossã¨accã®è¨ˆç®—\n",
        "            loss = criterion(outputs, labels)\n",
        "            valid_loss += loss.item()\n",
        "            acc = (outputs.max(1)[1] == labels).sum()\n",
        "            valid_acc += acc.item()\n",
        "    \n",
        "    # lossã¨accã®å¹³å‡ã‚’è¨ˆç®—\n",
        "    avg_valid_loss = valid_loss / len(valid_loader.dataset)\n",
        "    avg_valid_acc = valid_acc / len(valid_loader.dataset)\n",
        "    \n",
        "    # ãƒ­ã‚°ã®å‡ºåŠ›\n",
        "    print (\n",
        "        f'train_loss: {avg_train_loss:.4f}, train_acc: {avg_train_acc:.4f}, ' \\\n",
        "        f'val_loss: {avg_valid_loss:.4f}, val_acc: {avg_valid_acc:.4f}' \n",
        "    )\n",
        "\n",
        "    # ä¸€ç•ªlossãŒä½ã„ã‚¨ãƒãƒƒã‚¯ã®é‡ã¿ã‚’ä¿å­˜\n",
        "    if avg_valid_loss < min_valid_loss:\n",
        "        print('Save best model ...')\n",
        "        min_valid_loss = avg_valid_loss\n",
        "        torch.save(model.state_dict(), 'food20_best.ckpt')\n",
        "\n",
        "    print('====================')\n",
        "     \n",
        "    # ã‚°ãƒ©ãƒ•è¡¨ç¤ºç”¨ãƒªã‚¹ãƒˆã«ä¿å­˜\n",
        "    train_loss_list.append(avg_train_loss)\n",
        "    train_acc_list.append(avg_train_acc)\n",
        "    valid_loss_list.append(avg_valid_loss)\n",
        "    valid_acc_list.append(avg_valid_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ã‚°ãƒ©ãƒ•ã®è¡¨ç¤º\n",
        "plt.figure()\n",
        "plt.plot(range(1, len(train_loss_list)+1), train_loss_list, color='blue', linestyle='-', label='train_loss')\n",
        "plt.plot(range(1, len(valid_loss_list)+1), valid_loss_list, color='green', linestyle='--', label='valid_loss')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.grid()\n",
        " \n",
        "plt.figure()\n",
        "plt.plot(range(1, len(train_acc_list)+1), train_acc_list, color='blue', linestyle='-', label='train_acc')\n",
        "plt.plot(range(1, len(valid_acc_list)+1), valid_acc_list, color='green', linestyle='--', label='valid_acc')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã®æº–å‚™"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Datasetã‚¯ãƒ©ã‚¹å®šç¾©\n",
        "\n",
        "import glob\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MyTestDataset(Dataset):\n",
        "    def __init__(self, test_image_dir, transform=None):\n",
        "        self.image_paths = glob.glob(test_image_dir + '/*.jpg')\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_path = self.image_paths[index]\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# ğŸ’¡è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¹\n",
        "test_path = '../input/test/'\n",
        "\n",
        "# DatasetåŒ–\n",
        "test_dataset = MyTestDataset(test_image_dir=test_path, transform=valid_transform)\n",
        "\n",
        "# DataLoaderåŒ–\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿\n",
        "best_model = Net()\n",
        "best_model.load_state_dict(torch.load('food20_best.ckpt'))\n",
        "best_model.to(device)\n",
        "\n",
        "# çµæœä¿å­˜ç”¨\n",
        "preds = []\n",
        "\n",
        "# è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰\n",
        "best_model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images in test_loader:\n",
        "        # deviceã¸è»¢é€      \n",
        "        images = images.to(device)\n",
        "        # ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›\n",
        "        outputs = best_model.forward(images)\n",
        "        # çµæœä¿å­˜\n",
        "        preds.append((torch.argmax(outputs, dim=1)).to('cpu').numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "out_df = pd.DataFrame()\n",
        "out_df['ImageName'] = [f'{str(i).zfill(4)}.jpg' for i in range(1, len(preds)+1)]\n",
        "out_df['Label'] = np.concatenate(preds, axis=0)\n",
        "\n",
        "out_df.to_csv('submission.csv', index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(preds)\n",
        "print(np.concatenate(preds, axis=0))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "week2-3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
