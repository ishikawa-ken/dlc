{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Food-20コンペ\n",
        "\n",
        "このファイルはこのままでも最低限動作するようになっています。\n",
        "\n",
        "ハイスコアを目指すには改良が必要です。改良ポイントには`# 💡なにかしら`とコメントがあります。\n",
        "\n",
        "| レベル感 | やること |\n",
        "| :--: | :-- |\n",
        "| **秀才** | そのまま提出してみよう。|\n",
        "| **天才** | このコードを改良して、ハイスコアを目指そう。 |\n",
        "| **鬼才** | 転移学習/FTに挑戦してみよう。 |\n",
        "| **奇才** | †更なる高みへ† |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BFooUB9-EXF",
        "outputId": "35bda307-a045-4c1a-caa0-89de75092583"
      },
      "outputs": [],
      "source": [
        "# # Googleドライブのマウント（Colab使いのみ）\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# %cd /content/drive/MyDrive/dlc/week3.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxGtp1xw-2cW"
      },
      "outputs": [],
      "source": [
        "# 図表が使えるようにする\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxDwH5Ao-t_a"
      },
      "source": [
        "## データの準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### データの読み込み\n",
        "\n",
        "```\n",
        "dataset1\n",
        "├── class1\n",
        "│   ├── a.jpg\n",
        "│   ├── ・・・\n",
        "│\n",
        "├── class2\n",
        "│   ├── a.jpg\n",
        "│   ├── ・・・\n",
        "・・・\n",
        "\n",
        "```\n",
        "↑のように、クラスに対応したディレクトリごとにデータが分けられている場合、torchvisionの[ImageFolder](https://pytorch.org/vision/main/generated/torchvision.datasets.ImageFolder.html)を利用できます。（自作Datasetクラスを作る必要がなくなる）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 読み込み処理\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# 💡訓練データのパス\n",
        "train_path = '../input/train/'\n",
        "\n",
        "# データセット化\n",
        "full_dataset = ImageFolder(train_path)\n",
        "\n",
        "# サイズ確認\n",
        "print(f'full size: {len(full_dataset)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 訓練データと検証データの割合を決めよう"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 訓練データと検証データに分割する\n",
        "\n",
        "import torch\n",
        "\n",
        "# 💡訓練データの割合\n",
        "train_ratio = 0.8\n",
        "\n",
        "# 各データの数を算出\n",
        "train_size = int(train_ratio * len(full_dataset))\n",
        "valid_size = len(full_dataset) - train_size\n",
        "\n",
        "# ランダムに分割\n",
        "train_dataset, valid_dataset = torch.utils.data.random_split(\n",
        "    full_dataset, [train_size, valid_size]\n",
        ")\n",
        "\n",
        "# サイズ確認\n",
        "print(f'train: {len(train_dataset)}, valid: {len(valid_dataset)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 前処理を定義しよう\n",
        "\n",
        "参考：\n",
        "\n",
        "* [Pytorch公式 - torchvision.transforms](https://pytorch.org/vision/stable/transforms.html)\n",
        "* [torchvision で使える Transform まとめ](https://pystyle.info/pytorch-list-of-transforms/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 前処理の定義\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "# 訓練データ用前処理\n",
        "train_transform = transforms.Compose([\n",
        "    # 💡色々試してみよう\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2009, 0.1984, 0.2023))\n",
        "])\n",
        "\n",
        "# 検証データ&テストデータ用前処理\n",
        "valid_transform = transforms.Compose([\n",
        "    # 💡色々試してみよう\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2009, 0.1984, 0.2023))\n",
        "])\n",
        "\n",
        "# 前処理の適用\n",
        "train_dataset.dataset.transform = train_transform\n",
        "valid_dataset.dataset.transform = valid_transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ミニバッチサイズを決めよう"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DataLoaderを作成\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 💡ミニバッチサイズ\n",
        "batch_size = 128\n",
        "\n",
        "# 訓練用データローダー\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# 検証用データローダー\n",
        "valid_loader = DataLoader(\n",
        "    dataset=valid_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 番号とクラスの辞書\n",
        "class_label = {\n",
        "    0 : 'apple_pie',\n",
        "    1 : 'cheesecake',\n",
        "    2 : 'chocolate_cake', \n",
        "    3 : 'donuts', \n",
        "    4 : 'french_fries',\n",
        "    5 : 'french_toast',\n",
        "    6 : 'fried_rice',\n",
        "    7 : 'hamburger',\n",
        "    8 : 'ice_cream',\n",
        "    9 : 'miso_soup',\n",
        "    10: 'oysters',\n",
        "    11: 'pizza',\n",
        "    12: 'ramen',\n",
        "    13: 'sashimi',\n",
        "    14: 'spaghetti_bolognese',\n",
        "    15: 'spaghetti_carbonara',\n",
        "    16: 'steak',\n",
        "    17: 'sushi',\n",
        "    18: 'takoyaki',\n",
        "    19: 'waffles'\n",
        "}\n",
        "\n",
        "# データローダから画像とラベルのテンソルを取り出す\n",
        "def showBatch(dl):\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    for images, labels in dl:\n",
        "        for i in range(5):\n",
        "            plt.subplot(1, 5, i+1)\n",
        "            plt.imshow(np.transpose(images[i].numpy(), (1, 2, 0)))\n",
        "            plt.title(class_label[int(labels[i].numpy())])\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# データの確認\n",
        "showBatch(train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ネットワークの準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ネットワークを構築しよう\n",
        "\n",
        "必要：\n",
        "\n",
        "* **[Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)** ... 畳み込み層\n",
        "* **[MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html)** ... 最大値プーリング層\n",
        "* **[Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)** ... 全結合層\n",
        "* **[Flatten](https://pytorch.org/docs/stable/generated/torch.flatten.html)** ... ベクトル化（全結合層前に入れる）\n",
        "* **[(activations)](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)** ... お好きな活性化関数\n",
        "\n",
        "アレンジ：\n",
        "* **[Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html)** ... ドロップアウト\n",
        "* **[BatchNorm2d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html)** ... バッチ正規化（2次元：Conv2d, MaxPool2dの直後）\n",
        "* **[BatchNorm1d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html)** ... バッチ正規化（1次元：Linearの直後）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ネットワーク定義\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# クラス数\n",
        "num_classes = 20\n",
        "\n",
        "# クラス定義\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        # 💡ネットワーク本体\n",
        "        self.network = nn.Sequential(\n",
        "            # 入力画像サイズ:3x128x128\n",
        "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # nn.BatchNorm2d(16),\n",
        "\n",
        "            # 16x64x64\n",
        "            nn.Conv2d(16, 32, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # 32x32x32\n",
        "            nn.Conv2d(32, 64, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # 64x16x16\n",
        "            nn.Conv2d(64, 128, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # 128x8x8\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128*8*8, 512),\n",
        "            # nn.Dropout(p=0.5),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            \n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    # 順伝搬\n",
        "    def forward(self, x):\n",
        "        return self.network(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# デバイスに転送\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = Net().to(device)\n",
        "\n",
        "# ネットワークの確認\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 損失関数と最適化手法を決めよう\n",
        "\n",
        "参考：\n",
        "\n",
        "* [torch.nn - Loss Functions（損失関数）](https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
        "* [torch.optim - Algorithms（最適化手法）](https://pytorch.org/docs/stable/optim.html#algorithms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 損失関数と最適化手法を設定\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "# 💡損失関数: 交差エントロピー\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 💡最適化手法: Adam\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 学習回数を決めよう"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 💡エポック数\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# lossとacc記録用リスト\n",
        "train_loss_list, train_acc_list, valid_loss_list, valid_acc_list = [], [], [], []\n",
        "\n",
        "# 最小loss保存用\n",
        "min_valid_loss = 10000000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### いざ学習"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 学習\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "print ('Training start ...')\n",
        "\n",
        "# 事前に行ったエポック数\n",
        "ad_epochs = len(train_loss_list)\n",
        " \n",
        "for epoch in tqdm(range(num_epochs), desc='Epoch'):\n",
        "    \n",
        "    # エポック数の通知\n",
        "    print(f'Epoch [{ad_epochs+epoch+1}/{ad_epochs+num_epochs}]')\n",
        "    \n",
        "    # エポックごとに初期化\n",
        "    train_loss, train_acc, valid_loss, valid_acc = 0, 0, 0, 0\n",
        "    \n",
        "    # ====== 訓練モード ======\n",
        "    model.train()\n",
        "\n",
        "    # ミニバッチの数実行\n",
        "    for images, labels in tqdm(train_loader, leave=False, desc='Train'):\n",
        "        # deviceへ転送\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        \n",
        "        # 勾配をリセット\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # 順伝搬の計算\n",
        "        outputs = model(images)\n",
        "        \n",
        "        # lossとaccの計算\n",
        "        loss = criterion(outputs, labels)\n",
        "        train_loss += loss.item()\n",
        "        acc = (outputs.max(1)[1] == labels).sum()\n",
        "        train_acc += acc.item()\n",
        "        \n",
        "        # 逆伝搬の計算\n",
        "        loss.backward()\n",
        "        # 重みの更新\n",
        "        optimizer.step()\n",
        "\n",
        "        # lossとaccの平均を計算\n",
        "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
        "        avg_train_acc = train_acc / len(train_loader.dataset)\n",
        "\n",
        "    \n",
        "    # ====== 検証モード ======\n",
        "    model.eval()\n",
        "    \n",
        "    # 必要のない計算を停止\n",
        "    with torch.no_grad():\n",
        "        # ミニバッチの数実行\n",
        "        for images, labels in tqdm(valid_loader, leave=False, desc='Valid'):\n",
        "            # deviceへ転送      \n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            \n",
        "            # モデル出力\n",
        "            outputs = model(images)\n",
        "            \n",
        "            # lossとaccの計算\n",
        "            loss = criterion(outputs, labels)\n",
        "            valid_loss += loss.item()\n",
        "            acc = (outputs.max(1)[1] == labels).sum()\n",
        "            valid_acc += acc.item()\n",
        "    \n",
        "    # lossとaccの平均を計算\n",
        "    avg_valid_loss = valid_loss / len(valid_loader.dataset)\n",
        "    avg_valid_acc = valid_acc / len(valid_loader.dataset)\n",
        "    \n",
        "    # ログの出力\n",
        "    print (\n",
        "        f'train_loss: {avg_train_loss:.4f}, train_acc: {avg_train_acc:.4f}, ' \\\n",
        "        f'val_loss: {avg_valid_loss:.4f}, val_acc: {avg_valid_acc:.4f}' \n",
        "    )\n",
        "\n",
        "    # 一番lossが低いエポックの重みを保存\n",
        "    if avg_valid_loss < min_valid_loss:\n",
        "        print('Save best model ...')\n",
        "        min_valid_loss = avg_valid_loss\n",
        "        torch.save(model.state_dict(), 'food20_best.ckpt')\n",
        "\n",
        "    print('====================')\n",
        "     \n",
        "    # グラフ表示用リストに保存\n",
        "    train_loss_list.append(avg_train_loss)\n",
        "    train_acc_list.append(avg_train_acc)\n",
        "    valid_loss_list.append(avg_valid_loss)\n",
        "    valid_acc_list.append(avg_valid_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# グラフの表示\n",
        "plt.figure()\n",
        "plt.plot(range(1, len(train_loss_list)+1), train_loss_list, color='blue', linestyle='-', label='train_loss')\n",
        "plt.plot(range(1, len(valid_loss_list)+1), valid_loss_list, color='green', linestyle='--', label='valid_loss')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.grid()\n",
        " \n",
        "plt.figure()\n",
        "plt.plot(range(1, len(train_acc_list)+1), train_acc_list, color='blue', linestyle='-', label='train_acc')\n",
        "plt.plot(range(1, len(valid_acc_list)+1), valid_acc_list, color='green', linestyle='--', label='valid_acc')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 提出ファイルの準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### テストデータの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Datasetクラス定義\n",
        "\n",
        "import glob\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MyTestDataset(Dataset):\n",
        "    def __init__(self, test_image_dir, transform=None):\n",
        "        self.image_paths = glob.glob(test_image_dir + '/*.jpg')\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_path = self.image_paths[index]\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 💡訓練データのパス\n",
        "test_path = '../input/test/'\n",
        "\n",
        "# Dataset化\n",
        "test_dataset = MyTestDataset(test_image_dir=test_path, transform=valid_transform)\n",
        "\n",
        "# DataLoader化\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 学習したモデルの読み込み\n",
        "best_model = Net()\n",
        "best_model.load_state_dict(torch.load('food20_best.ckpt'))\n",
        "best_model.to(device)\n",
        "\n",
        "# 結果保存用\n",
        "preds = []\n",
        "\n",
        "# 評価モード\n",
        "best_model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images in test_loader:\n",
        "        # deviceへ転送      \n",
        "        images = images.to(device)\n",
        "        # モデル出力\n",
        "        outputs = best_model.forward(images)\n",
        "        # 結果保存\n",
        "        preds.append((torch.argmax(outputs, dim=1)).to('cpu').numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "out_df = pd.DataFrame()\n",
        "out_df['ImageName'] = [f'{str(i).zfill(4)}.jpg' for i in range(1, len(preds)+1)]\n",
        "out_df['Label'] = np.concatenate(preds, axis=0)\n",
        "\n",
        "out_df.to_csv('submission.csv', index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(preds)\n",
        "print(np.concatenate(preds, axis=0))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "week2-3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
